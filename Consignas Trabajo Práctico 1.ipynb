{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKq-PKdSk9L_"
   },
   "source": [
    "# TP 1 - Naive Bayes\n",
    "\n",
    "El siguiente trabajo práctico consta de dos ejercicios relacionados con el primer modulo visto en clase.\n",
    "\n",
    "Fecha de entrega: Domingo 4 de abril 23:59 hs\n",
    "\n",
    "Fecha de defensa: Lunes 5 de abril en horario de clase\n",
    "\n",
    "# **Para ambos ejercicios desarrollar el código propio del clasificador**\n",
    "\n",
    "Se pueden utilizar librerias para la etapa de limpieza de los datos. Para el clasificador propiamente dicho, tiene que ser implementado completamente. Pueden basarse en notebooks vistas en clase u otros materiales, pero es requisito que entiendan cómo funciona el código que utilicen.\n",
    "\n",
    "Por último, se recomienda validar el funcionamiento de los mismos utilizando algún clasificador de una librería como Sklear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dn-8_3FAlZnC"
   },
   "source": [
    "##Ejercicio 1\n",
    "\n",
    "Realizar un clasificador de noticias utilizando el conjunto de datos de fetch_20newsgroups de Sklearn. A continuación, encontrarán el código para poder obtener el dataset.\n",
    "\n",
    "\n",
    "Recordar elegir una métrica para medir el desempeño del modelo y validar los resultados. \n",
    "\n",
    "Explicar paso a paso que es lo que se va desarrollando.\n",
    "\n",
    "**Incluir una explicación sobre Laplacian smoothing y para qué se utiliza** (evaluar su aplicación en la resolución de la consigna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2rI3eqbk5T2",
    "outputId": "ac39ce7a-a3bd-4598-f441-1c57a76d695e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "#Cargando dataset - training data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSqNMGWPpbd8"
   },
   "source": [
    "##Ejercicio 2\n",
    "\n",
    "A partir del Pima Indians Diabetes Dataset predecir la aparición de diabetes basado en diferentes valores diagnósticos.\n",
    "\n",
    "Este conjunto de datos es del  National Institute of Diabetes and Digestive and Kidney Diseases originalmente. \n",
    "\n",
    "Posee ciertas limitaciones para la selección de los pacientes a partir de una base de datos más grande. En particular, son todos pacientes femeninos de al menos 21 años de edad de herencia Pima Indian.\n",
    "\n",
    "Las variables:\n",
    "\n",
    "\n",
    "*   Pregnancies (embarazos): Número de embarazos\n",
    "*   Glucose: Concentración de glucosa en sangre a 2 horas de una prueba de tolerancia de glucosa oral.\n",
    "*   BloodPresure (Presión sanguinea): Presión diastólica (mm Hg)\n",
    "*   SkinThickness: Tamaño del pliege de la piel del triceps\n",
    "*   Insulin: Insulina en sangre a 2 horas (mu U/ml)\n",
    "*   BMI: Indice de masa corporal (peso en kg / (altura en metros)^2)\n",
    "*   DiabetesPedigreeFunction: Una función que estima el likelihood de tener diabetes dado el historial familiar\n",
    "*   Age: Edad (años)\n",
    "*   Outcome: Variable 0 o 1 (0 no posee diabtes, 1 posee diabetes)\n",
    "\n",
    "Este ejercicio consta de dos partes:\n",
    "\n",
    "\n",
    "\n",
    "1.   Realizar un EDA completo de este dataset incluyendo: cantidad de valores nulos de las variables, número de personas para cada clase, análisis de distribuciones de las variables (por ejemplo se pueden usar histogramas), análisis de outliers y correlación entre variables. Recordar explicar las diferentes decisiones que se vayan tomando respecto de la limpieza y calidad de los datos\n",
    "2.   Generar un clasificador utilizando las variables que se consideren óptimas. Recordar elegir una métrica para medir el desempeño del modelo y validar los resultados. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TP 1 - Naive Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
